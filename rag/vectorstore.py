# rag/vectorstore.py (CODE ƒê√É S·ª¨A L·ªñI V√Ä T·ªêI ∆ØU)

from langchain_chroma import Chroma
from rag.embeddings import get_embeddings # Gi·ªØ import n√†y
import config
import os
import shutil
from .data_loader import load_data 
# üõë X√ìA D√íNG N√ÄY: from langchain_ollama import OllamaEmbeddings 
from langchain_core.documents import Document

def get_vectorstore():
    # H√†m n√†y OK, s·ª≠ d·ª•ng get_embeddings() ƒë√£ c·∫•u h√¨nh mxbai-embed-large
    embeddings = get_embeddings()
    return Chroma(
        persist_directory=config.VECTOR_STORE_PATH,
        embedding_function=embeddings
    )
    
def update_vectorstore():
    global vectorstore
    vectorstore_path = config.VECTOR_STORE_PATH
    if os.path.exists(vectorstore_path):
        shutil.rmtree(vectorstore_path, ignore_errors=True)
    
    texts = load_data("data/knowledge.txt")
    if not texts:
        raise ValueError("Kh√¥ng c√≥ d·ªØ li·ªáu trong file knowledge.txt")
    
    # L·∫•y m√¥ h√¨nh embedding ƒë√£ c·∫•u h√¨nh (mxbai-embed-large)
    embeddings = get_embeddings() 
    
    # X·ª≠ l√Ω n·ªôi dung Documents (Ch·ªâ l·∫•y chu·ªói n·ªôi dung)
    if isinstance(texts[0], Document):
        text_contents = [doc.page_content for doc in texts]
    else:
        text_contents = texts
    
    # S·ª≠ d·ª•ng h√†m from_texts v·ªõi m√¥ h√¨nh EMBEDDING ƒë√£ c·∫•u h√¨nh ƒë√∫ng
    vectorstore = Chroma.from_texts(text_contents, embeddings, persist_directory=vectorstore_path)
    print(f"Vector store ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t t·∫°i {vectorstore_path}")
