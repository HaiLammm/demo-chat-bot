import json
import os
from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate

# Model Ollama c·ªßa b·∫°n
llm = ChatOllama(model="cv-analyzer", temperature=0.3)

# Prompt chu·∫©n t·ª´ tr∆∞·ªõc (thay {context} b·∫±ng knowledge.txt n·∫øu c√≥)
prompt_template = """
B·∫°n l√† chuy√™n gia CV Vi·ªát Nam. Ph√¢n t√≠ch CV sau cho ng√†nh {industry}:
CV JSON: {cv_json}

Output ng·∫Øn g·ªçn: ƒêi·ªÉm m·∫°nh | ƒêi·ªÉm y·∫øu | Top 3 k·ªπ nƒÉng b·ªï sung (kh√¥ng b·ªãa tech n·∫øu kh√¥ng c√≥).
"""

chain = PromptTemplate.from_template(prompt_template) | llm

# Test t·∫•t c·∫£ 50 file
test_folder = "cv_testset"
results = []
for filename in os.listdir(test_folder):
    if filename.endswith('.json'):
        with open(os.path.join(test_folder, filename), 'r', encoding='utf-8') as f:
            cv_data = json.load(f)
        industry = filename.split('_')[-1].replace('.json', '').replace('_', ' ')
        result = chain.invoke({
            "cv_json": json.dumps(cv_data, ensure_ascii=False),
            "industry": industry
        })
        results.append(f"File {filename}: {result.content[:200]}...")  # Log ng·∫Øn
        print(f"Tested {filename} - Output: {result.content[:100]}...")

with open("test_results.txt", "w", encoding="utf-8") as f:
    f.write("\n".join(results))

danger_words = ["AWS", "Python", "NextJs", "SaaS", "Tech Sales", "Microsoft", "Google Cloud", "AI", "ML", "Docker"]
danger_count = sum(1 for line in open("test_results.txt", encoding="utf-8") 
                   if any(word.lower() in line.lower() for word in danger_words))

print(f"\nüéØ K·∫æT QU·∫¢ TEST 50 CV")
print(f"   Hallucination rate: {danger_count}/50 ‚Üí {(danger_count/50)*100}%")
if danger_count == 0:
    print("   üöÄ BOT S·∫†CH 100% ‚Äì TH·∫¢ RA DISCORD NGAY V√Ä LU√îN!")
else:
    print(f"   ‚ö†Ô∏è  C√≤n {danger_count} tr∆∞·ªùng h·ª£p ·∫£o ‚Üí m·ªü test_results.txt s·ª≠a prompt ti·∫øp!")
